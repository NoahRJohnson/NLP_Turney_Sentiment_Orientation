{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews\n",
    "\n",
    "We will implement Turney's algorithm ([paper](http://www.aclweb.org/anthology/P02-1053.pdf)) for classifying movie reviews as positive or negative. Rather than deal with the headache of web search querying, we'll use a local data set as a corpus for querying. [IMDB reviews](https://www.kaggle.com/utathya/imdb-review-dataset) will be for our \"web search\", and [this polarity dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz) will be used for testing the classifier. It's important that there's no signal leakage between our two data sets, thus using data from two different sources rather than performing a train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Corpus\n",
    "\n",
    "Load the corpus for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Once again Mr. Costner has dragged out a movie...\n",
      "1    This is an example of why the majority of acti...\n",
      "2    First of all I hate those moronic rappers, who...\n",
      "3    Not even the Beatles could write songs everyon...\n",
      "4    Brass pictures (movies is not a fitting word f...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Large corpus of IMDB movie reviews. Comes labeled\n",
    "# but we will only use the raw text of the reviews\n",
    "# our classifier will \"query\" this data\n",
    "QUERY_FILE = \"train/imdb_master.csv\"\n",
    "\n",
    "# Use pandas to make our lives easier\n",
    "query_corpus = pd.read_csv(QUERY_FILE, encoding = 'cp1252')  # https://en.wikipedia.org/wiki/Windows-1252\n",
    "query_corpus = query_corpus['review']  # select just the text\n",
    "print(query_corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:32<00:00, 657.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Once, again, Mr., Costner, has, dragged, out,...\n",
      "1    [This, is, an, example, of, why, the, majority...\n",
      "2    [First, of, all, I, hate, those, moronic, rapp...\n",
      "3    [Not, even, the, Beatles, could, write, songs,...\n",
      "4    [Brass, pictures, (, movies, is, not, a, fitti...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tokenize each document in our corpus\n",
    "query_corpus_tokens = []\n",
    "for document in tqdm(query_corpus):\n",
    "    query_corpus_tokens.append(nltk.word_tokenize(document))\n",
    "\n",
    "query_corpus_tokens = pd.Series(query_corpus_tokens)\n",
    "print(query_corpus_tokens.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct helper functions to query our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits(w):\n",
    "    \"\"\"\n",
    "    Query our corpus for the number\n",
    "    of occurrences of token w.\n",
    "    \"\"\"\n",
    "    global query_corpus_tokens\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for token_list in query_corpus_tokens:\n",
    "        for token in token_list:\n",
    "            if token == w:\n",
    "                count += 1\n",
    "                \n",
    "    return count + 0.01  # no zeros\n",
    "\n",
    "def hits_near(phrase, w, nearness_threshold=10):\n",
    "    \"\"\"\n",
    "    Query our corpus for how often phrase is within\n",
    "    nearness_threshold tokens of w.\n",
    "    \"\"\"\n",
    "    global query_corpus_tokens\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for token_list in query_corpus_tokens:\n",
    "        for i in range(len(token_list)):\n",
    "            token = token_list[i]\n",
    "            if token == w:\n",
    "                tokens_to_left = token_list[max(i-nearness_threshold,0):i]\n",
    "                tokens_to_right = token_list[i+1:i+nearness_threshold]\n",
    "                \n",
    "                for context in [tokens_to_left, tokens_to_right]:\n",
    "                    for bigram in zip(context[:-1], context[1:]):\n",
    "                        if bigram == phrase:\n",
    "                            count += 1\n",
    "\n",
    "    return count + 0.01  # no zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct classifier\n",
    "\n",
    "Following the paper, there are three steps in the classification algorithm. Let's code up functions to do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The first step of the algorithm is to extract phrases containing adjectives or adverbs.\"\n",
    "\n",
    "We'll use the [NLTK POS tagger](https://www.nltk.org/book/ch05.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_tag_pattern(pos1, pos2, pos3):\n",
    "    \"\"\"\n",
    "    Manually check for patterns in Table 1 of the paper\n",
    "    \"\"\"\n",
    "    if pos1 == 'JJ':\n",
    "        if pos2 == 'JJ' and pos3 not in ['NN', 'NNS']:\n",
    "            # pattern 3\n",
    "            return True\n",
    "        elif pos2 in ['NN', 'NNS']:\n",
    "            # pattern 1\n",
    "            return True\n",
    "    elif pos1 in ['RB', 'RBR', 'RBS']:\n",
    "        if pos2 == 'JJ' and pos3 not in ['NN', 'NNS']:\n",
    "            # pattern 2\n",
    "            return True\n",
    "        elif pos2 in ['VB', 'VBD', 'VBN', 'VBG']:\n",
    "            # pattern 5\n",
    "            return True\n",
    "    elif pos1 in ['NN', 'NNS']:\n",
    "        if pos2 == 'JJ' and pos3 not in ['NN', 'NNS']:\n",
    "            # pattern 4\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def extract_all_phrases(review):\n",
    "    \"\"\"\n",
    "    Generator which extracts all two-word phrases\n",
    "    that fit Turney's pattern of tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_tokens = nltk.word_tokenize(review)\n",
    "    review_pos = nltk.pos_tag(review_tokens)\n",
    "    \n",
    "    # Loop through all trigrams checking for phrases\n",
    "    for (token1, pos1), (token2, pos2), (token3, pos3) in zip(review_pos[:-2],\n",
    "                                                              review_pos[1:-1],\n",
    "                                                              review_pos[2:]):\n",
    "        if matches_tag_pattern(pos1, pos2, pos3):\n",
    "            yield (token1, token2)\n",
    "\n",
    "    # Check last two-word phrase in review, with a blank 3rd pos\n",
    "    if matches_tag_pattern(review_pos[-2][1], review_pos[-1][1], ''):\n",
    "        yield (review_pos[-2][0], review_pos[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The second step is to estimate the semantic orientation of the extracted phrases, using the PMI-IR algorithm.\"\n",
    "\n",
    "The Pointwise Mutual Information-Information Retrieval (PMI-IR) algorithm uses the following formula:\n",
    "\n",
    "$$\n",
    "SO(phrase) = log_2(\\frac{hits(phrase\\ NEAR\\ \"excellent\") * hits(\"poor\")}{hits(phrase\\ NEAR\\ \"poor\") * hits(\"excellent\")})\n",
    "$$\n",
    "\n",
    "for some nearness threshold. Notice the implicit positive and negative seeds of \"excellent\" and \"poor\" respectively.\n",
    "\n",
    "Here is where the hits* functions we previously made for querying our corpus will come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "POSITIVE_SEED = \"excellent\"\n",
    "NEGATIVE_SEED = \"poor\"\n",
    "\n",
    "hits_positive = hits(POSITIVE_SEED)\n",
    "hits_negative = hits(NEGATIVE_SEED)\n",
    "\n",
    "def compute_SO(phrase):\n",
    "    \"\"\"\n",
    "    Compute the semantic orientation for a phrase by querying our corpus.\n",
    "    \"\"\"\n",
    "    global POSITIVE_SEED, NEGATIVE_SEED, hits_positive, hits_negative\n",
    "    \n",
    "    hits_phrase_near_positive = hits_near(phrase, POSITIVE_SEED)\n",
    "    hits_phrase_near_negative = hits_near(phrase, NEGATIVE_SEED)\n",
    "    \n",
    "    if hits_phrase_near_positive < 4 and hits_phrase_near_negative < 4:\n",
    "        # skip phrase\n",
    "        return 0\n",
    "    \n",
    "    OR = (hits_phrase_near_positive * hits_negative) / (hits_phrase_near_negative * hits_positive)\n",
    "    \n",
    "    SO = np.log(OR)\n",
    "    \n",
    "    return SO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The third step is to calculate the average semantic orientation of the phrases in the given review...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    \"\"\"\n",
    "    Return an average sentiment orien\n",
    "    \"\"\"\n",
    "    SO_sum = 0\n",
    "    n_sentences = 0\n",
    "    for phrase in extract_all_phrases(review):\n",
    "        SO_sum += compute_SO(phrase)\n",
    "        n_sentences += 1\n",
    "    \n",
    "    SO_avg = SO_sum / n_sentences\n",
    "    \n",
    "    return SO_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average SO of each review, and compare to its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [28:06<55:59:42, 203.62s/it]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/1000 [02:45<45:53:02, 165.35s/it]\u001b[A\n",
      "  0%|          | 2/1000 [03:53<37:44:47, 136.16s/it]\u001b[A\n",
      "  0%|          | 3/1000 [05:32<34:39:55, 125.17s/it]\u001b[A\n",
      "  0%|          | 4/1000 [08:13<37:32:38, 135.70s/it]\u001b[A\n",
      "  0%|          | 5/1000 [10:42<38:36:21, 139.68s/it]\u001b[A\n",
      "  1%|          | 6/1000 [13:26<40:38:11, 147.17s/it]\u001b[A\n",
      "  1%|          | 7/1000 [16:00<41:08:24, 149.15s/it]\u001b[A\n",
      "  1%|          | 8/1000 [17:47<37:37:45, 136.56s/it]\u001b[A\n",
      "  1%|          | 9/1000 [18:48<31:17:20, 113.66s/it]\u001b[A\n",
      "  1%|          | 10/1000 [19:16<24:15:31, 88.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.917250\n",
      "ACCURACY = 0.727273\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# These test folders contain labeled movie reviews\n",
    "TEST_POS_FOLDER = \"test/pos\"\n",
    "TEST_NEG_FOLDER = \"test/neg\"\n",
    "\n",
    "y = []\n",
    "y_hat = []\n",
    "\n",
    "NUM_REVIEWS_TO_TEST = 10  # classifying is very slow, so this is for debugging\n",
    "\n",
    "\n",
    "for class_folder, label in [(TEST_POS_FOLDER, 1), (TEST_NEG_FOLDER, -1)]:\n",
    "    review_fns = os.listdir(class_folder)\n",
    "    test_i = 0\n",
    "    for review_fn in tqdm(review_fns):\n",
    "        try:\n",
    "            with open(os.path.join(class_folder, review_fn), 'r') as f:\n",
    "                review = f.read()\n",
    "        except IOError:\n",
    "            print(\"Error reading %s\" % review_fn)\n",
    "            continue\n",
    "\n",
    "        review_SO_avg = classify_review(review)\n",
    "\n",
    "        y.append(label)\n",
    "        y_hat.append(review_SO_avg)\n",
    "\n",
    "        test_i += 1\n",
    "        if test_i > NUM_REVIEWS_TO_TEST:\n",
    "            break\n",
    "            \n",
    "y = np.array(y)\n",
    "y_hat = np.array(y_hat)\n",
    "y_hat_categorical = np.array(list(map(lambda x: 1 if x >= 0 else -1, y_hat)))\n",
    "\n",
    "print(\"MSE = %f\" % np.mean(np.square(y - y_hat)))\n",
    "print(\"ACCURACY = %f\" % np.mean(np.equal(y, y_hat_categorical)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our test set is evenly split between positive and negative reviews (1000 samples in each class), the baseline accuracy is 50%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
