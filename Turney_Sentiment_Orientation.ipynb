{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews\n",
    "\n",
    "We will implement Turney's algorithm ([paper](http://www.aclweb.org/anthology/P02-1053.pdf)) for classifying movie reviews as positive or negative. Rather than deal with the headache of web search querying, we'll use a local data set as a corpus for querying. [IMDB reviews](https://www.kaggle.com/utathya/imdb-review-dataset) will be for our \"web search\", and [this polarity dataset](http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz) will be used for testing the classifier. It's important that there's no signal leakage between our two data sets, thus using data from two different sources rather than performing a train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Corpus\n",
    "\n",
    "Load the corpus for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Once again Mr. Costner has dragged out a movie...\n",
      "1    This is an example of why the majority of acti...\n",
      "2    First of all I hate those moronic rappers, who...\n",
      "3    Not even the Beatles could write songs everyon...\n",
      "4    Brass pictures (movies is not a fitting word f...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Large corpus of IMDB movie reviews. Comes labeled\n",
    "# but we will only use the raw text of the reviews\n",
    "# our classifier will \"query\" this data\n",
    "QUERY_FILE = \"train/imdb_master.csv\"\n",
    "\n",
    "# Use pandas to make our lives easier\n",
    "query_corpus = pd.read_csv(QUERY_FILE, encoding = 'cp1252')  # https://en.wikipedia.org/wiki/Windows-1252\n",
    "query_corpus = query_corpus['review']  # select just the text\n",
    "print(query_corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink the corpus to a manageable size (or do some performance bottleneck profiling + optimization)\n",
    "query_corpus = query_corpus.head(n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 673.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Once, again, Mr., Costner, has, dragged, out,...\n",
      "1    [This, is, an, example, of, why, the, majority...\n",
      "2    [First, of, all, I, hate, those, moronic, rapp...\n",
      "3    [Not, even, the, Beatles, could, write, songs,...\n",
      "4    [Brass, pictures, (, movies, is, not, a, fitti...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tokenize each document in our corpus\n",
    "query_corpus_tokens = []\n",
    "for document in tqdm(query_corpus):\n",
    "    query_corpus_tokens.append(nltk.word_tokenize(document))\n",
    "\n",
    "query_corpus_tokens = pd.Series(query_corpus_tokens)\n",
    "print(query_corpus_tokens.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct helper functions to query our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2119.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Compute unigram counts across all documents in the corpus\n",
    "query_unigram_counts = Counter()\n",
    "\n",
    "for document in tqdm(query_corpus_tokens):\n",
    "    query_unigram_counts += Counter(document)\n",
    "\n",
    "def hits(w):\n",
    "    \"\"\"\n",
    "    Query our corpus for the number\n",
    "    of occurrences of token w.\n",
    "    \"\"\"\n",
    "    global query_unigram_counts\n",
    "    \n",
    "    return query_unigram_counts.get(w, 0.01)\n",
    "\n",
    "def hits_near(phrase, w, nearness_threshold=10):\n",
    "    \"\"\"\n",
    "    Query our corpus for how often phrase is within\n",
    "    nearness_threshold tokens of w.\n",
    "    \"\"\"\n",
    "    global query_corpus_tokens\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for token_list in query_corpus_tokens:\n",
    "        for i in range(len(token_list)):\n",
    "            token = token_list[i]\n",
    "            if token == w:\n",
    "                tokens_to_left = token_list[max(i-nearness_threshold,0):i]\n",
    "                tokens_to_right = token_list[i+1:i+nearness_threshold]\n",
    "                \n",
    "                for context in [tokens_to_left, tokens_to_right]:\n",
    "                    for bigram in zip(context[:-1], context[1:]):\n",
    "                        if bigram == phrase:\n",
    "                            count += 1\n",
    "\n",
    "    return count + 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct classifier\n",
    "\n",
    "Following the paper, there are three steps in the classification algorithm. Let's code up functions to do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The first step of the algorithm is to extract phrases containing adjectives or adverbs.\"\n",
    "\n",
    "We'll use the [NLTK POS tagger](https://www.nltk.org/book/ch05.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_tag_pattern(pos1, pos2, pos3):\n",
    "    \"\"\"\n",
    "    Manually check for patterns in Table 1 of the paper\n",
    "    \"\"\"\n",
    "    if pos1 == 'JJ':\n",
    "        if pos2 == 'JJ' and pos3 not in ['NN', 'NNS']:\n",
    "            # pattern 3\n",
    "            return True\n",
    "        elif pos2 in ['NN', 'NNS']:\n",
    "            # pattern 1\n",
    "            return True\n",
    "    elif pos1 in ['RB', 'RBR', 'RBS']:\n",
    "        if pos2 == 'JJ' and pos3 not in ['NN', 'NNS']:\n",
    "            # pattern 2\n",
    "            return True\n",
    "        elif pos2 in ['VB', 'VBD', 'VBN', 'VBG']:\n",
    "            # pattern 5\n",
    "            return True\n",
    "    elif pos1 in ['NN', 'NNS']:\n",
    "        if pos2 == 'JJ' and pos3 not in ['NN', 'NNS']:\n",
    "            # pattern 4\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def extract_all_phrases(review):\n",
    "    \"\"\"\n",
    "    Generator which extracts all two-word phrases\n",
    "    that fit Turney's pattern of tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_tokens = nltk.word_tokenize(review)\n",
    "    review_pos = nltk.pos_tag(review_tokens)\n",
    "    \n",
    "    # Loop through all trigrams checking for phrases\n",
    "    for (token1, pos1), (token2, pos2), (token3, pos3) in zip(review_pos[:-2],\n",
    "                                                              review_pos[1:-1],\n",
    "                                                              review_pos[2:]):\n",
    "        if matches_tag_pattern(pos1, pos2, pos3):\n",
    "            yield (token1, token2)\n",
    "\n",
    "    # Check last two-word phrase in review, with a blank 3rd pos\n",
    "    if matches_tag_pattern(review_pos[-2][1], review_pos[-1][1], ''):\n",
    "        yield (review_pos[-2][0], review_pos[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The second step is to estimate the semantic orientation of the extracted phrases, using the PMI-IR algorithm.\"\n",
    "\n",
    "The Pointwise Mutual Information-Information Retrieval (PMI-IR) algorithm uses the following formula:\n",
    "\n",
    "$$\n",
    "SO(phrase) = log_2(\\frac{hits(phrase\\ NEAR\\ \"excellent\") * hits(\"poor\")}{hits(phrase\\ NEAR\\ \"poor\") * hits(\"excellent\")})\n",
    "$$\n",
    "\n",
    "for some nearness threshold. Notice the implicit positive and negative seeds of \"excellent\" and \"poor\" respectively.\n",
    "\n",
    "Here is where the hits* functions we previously made for querying our corpus will come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "POSITIVE_SEED = \"excellent\"\n",
    "NEGATIVE_SEED = \"poor\"\n",
    "\n",
    "hits_positive = hits(POSITIVE_SEED)\n",
    "hits_negative = hits(NEGATIVE_SEED)\n",
    "\n",
    "def compute_SO(phrase):\n",
    "    \"\"\"\n",
    "    Compute the semantic orientation for a phrase by querying our corpus.\n",
    "    \"\"\"\n",
    "    global POSITIVE_SEED, NEGATIVE_SEED, hits_positive, hits_negative\n",
    "    \n",
    "    hits_phrase_near_positive = hits_near(phrase, POSITIVE_SEED)\n",
    "    hits_phrase_near_negative = hits_near(phrase, NEGATIVE_SEED)\n",
    "    \n",
    "    if hits_phrase_near_positive < 4 and hits_phrase_near_negative < 4:\n",
    "        # skip phrase\n",
    "        return 0\n",
    "    \n",
    "    OR = (hits_phrase_near_positive * hits_negative) / (hits_phrase_near_negative * hits_positive)\n",
    "    \n",
    "    SO = np.log(OR)\n",
    "    \n",
    "    return SO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The third step is to calculate the average semantic orientation of the phrases in the given review...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    \"\"\"\n",
    "    Return an average sentiment orien\n",
    "    \"\"\"\n",
    "    SO_sum = 0\n",
    "    n_sentences = 0\n",
    "    for phrase in extract_all_phrases(review):\n",
    "        SO_sum += compute_SO(phrase)\n",
    "        n_sentences += 1\n",
    "    \n",
    "    SO_avg = SO_sum / n_sentences\n",
    "    \n",
    "    return SO_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average SO of each review, and compare to its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 436/1000 [05:50<08:55,  1.05it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-84bc34e6bd3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mreview_SO_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-65dc5fa81370>\u001b[0m in \u001b[0;36mclassify_review\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextract_all_phrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mSO_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompute_SO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mn_sentences\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-07312d994469>\u001b[0m in \u001b[0;36mcompute_SO\u001b[0;34m(phrase)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mhits_phrase_near_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPOSITIVE_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhits_phrase_near_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEGATIVE_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhits_phrase_near_positive\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhits_phrase_near_negative\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-872f6763d25b>\u001b[0m in \u001b[0;36mhits_near\u001b[0;34m(phrase, w, nearness_threshold)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_corpus_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mtokens_to_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnearness_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# These test folders contain labeled movie reviews\n",
    "TEST_POS_FOLDER = \"test/pos\"\n",
    "TEST_NEG_FOLDER = \"test/neg\"\n",
    "\n",
    "y = []\n",
    "y_hat = []\n",
    "\n",
    "pos_review_fns = os.listdir(TEST_POS_FOLDER)\n",
    "for pos_review_fn in tqdm(pos_review_fns):\n",
    "    with open(os.path.join(TEST_POS_FOLDER, pos_review_fn), 'r') as f:\n",
    "        review = f.read()\n",
    "\n",
    "    review_SO_avg = classify_review(review)\n",
    "    \n",
    "    y.append(1)\n",
    "    y_hat.append(review_SO_avg)\n",
    "\n",
    "neg_review_fns = os.listdir(TEST_NEG_FOLDER)\n",
    "for neg_review_fn in tqdm(neg_review_fns):\n",
    "    with open(os.path.join(TEST_NEG_FOLDER, neg_review_fn), 'r') as f:\n",
    "        review = f.read()\n",
    "\n",
    "    review_SO_avg = classify_review(review)\n",
    "    \n",
    "    y.append(-1)\n",
    "    y_hat.append(review_SO_avg)\n",
    "\n",
    "y = np.array(y)\n",
    "y_hat = np.array(y_hat)\n",
    "y_hat_categorical = np.array(list(map(lambda x: 1 if x >= 0 else -1, y_hat)))\n",
    "\n",
    "print(\"MSE = %f\" % np.mean(np.square(y - y_hat)))\n",
    "print(\"ACCURACY = %f\" % np.mean(np.equal(y, y_hat_categorical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_hat_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our test set is evenly split between positive and negative reviews (1000 samples in each class), the baseline accuracy is 50%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
